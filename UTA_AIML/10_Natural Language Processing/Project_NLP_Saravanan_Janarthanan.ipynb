{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUwiNpq292GL"
   },
   "source": [
    "#Project Natural Language Processing#\n",
    "\n",
    "DOMAIN: Digital content management\n",
    "\n",
    "• CONTEXT: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc.\n",
    "are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a\n",
    "classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "• DATA DESCRIPTION: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "• For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "date of the following post and links within a post are denoted by the label url link.\n",
    "\n",
    "• PROJECT OBJECTIVE: To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYj0a0wE-C3j"
   },
   "source": [
    "***Q 1. Read and Analyse Dataset.***\n",
    "\n",
    "     A. Clearly write outcome of data analysis(Minimum 2 points)\n",
    "\n",
    "     B. Clean the Structured Data \n",
    "       *   Missing value analysis and imputation.\n",
    "       *   Eliminate Non-English textual data.\n",
    "\n",
    "\n",
    "\n",
    "Hint: Refer ‘langdetect’ library to detect language of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DRwrYVmh_Dbn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-LlFePv_lGz",
    "outputId": "91074ae5-233e-4485-a290-6ba654aaa1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2UhMpoIo_oYs"
   },
   "outputs": [],
   "source": [
    "project_path = '/content/drive/My Drive/Colab Notebooks/NLTP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sMRvcL00_2qL"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WV832UlKF6tx"
   },
   "outputs": [],
   "source": [
    "blog_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/NLTP/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mBjOeG0rEjyz",
    "outputId": "6c43cb4e-3cb8-47b8-e4a1-d2ecf8ebc47e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d75c4058-9d4c-496c-90a5-67ff5d0a58d8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29489</th>\n",
       "      <td>3866560</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>hello everyone, i said earlier that i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629883</th>\n",
       "      <td>3131734</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>Happy happy~~!! Today is a happy day fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281010</th>\n",
       "      <td>958176</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>02,June,2004</td>\n",
       "      <td>Heheh. Good heavens, childe. This sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424094</th>\n",
       "      <td>1298624</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>21,August,2003</td>\n",
       "      <td>...and it arrives today?!   My l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245647</th>\n",
       "      <td>1237310</td>\n",
       "      <td>male</td>\n",
       "      <td>38</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>27,June,2004</td>\n",
       "      <td>A PLACE IN THE SUN (1951)  Direct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d75c4058-9d4c-496c-90a5-67ff5d0a58d8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d75c4058-9d4c-496c-90a5-67ff5d0a58d8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d75c4058-9d4c-496c-90a5-67ff5d0a58d8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id gender  age        topic         sign            date  \\\n",
       "29489   3866560   male   17       indUnk       Pisces    09,July,2004   \n",
       "629883  3131734   male   24  Engineering  Sagittarius    03,July,2004   \n",
       "281010   958176   male   17   Non-Profit       Gemini    02,June,2004   \n",
       "424094  1298624   male   25   Technology        Aries  21,August,2003   \n",
       "245647  1237310   male   38         Arts       Taurus    27,June,2004   \n",
       "\n",
       "                                                     text  \n",
       "29489          hello everyone, i said earlier that i w...  \n",
       "629883         Happy happy~~!! Today is a happy day fo...  \n",
       "281010         Heheh. Good heavens, childe. This sound...  \n",
       "424094                ...and it arrives today?!   My l...  \n",
       "245647               A PLACE IN THE SUN (1951)  Direct...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df = blog_df.sample(frac=0.1, random_state=5)\n",
    "blog_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAjQzcCNJdxZ",
    "outputId": "6ba4b677-7bae-4e61-9bce-9b519be9e4fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68128, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdmvJRy_JEU9"
   },
   "source": [
    "***Ans 1***\n",
    "\n",
    "The Data has 7 columns\n",
    "- id - represnting the user\n",
    "- geneder - a categorical data\n",
    "- age     - a continious numeric data \n",
    "- topic   - a categorical variable that represents the user type\n",
    "- sign    - a categorial data that represents the zodiac signs\n",
    "- date    - Date value\n",
    "- text    - String data - The blog text the user has submitted \n",
    "\n",
    "There are 681284 rows in the dataset.\n",
    "\n",
    "'Student' and 'indUnk' topic has major inputs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_E9gP9IZKcdq",
    "outputId": "2bb4164d-b1fc-429c-adbb-8b56fae460fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7p_dLhOt4YW",
    "outputId": "8abf16a1-32a7-4f4f-9816-d97e24ab7c49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mTCSfbmR3nnl"
   },
   "outputs": [],
   "source": [
    "# reomove any characters that has ascii value greater than 127 for non-English character\n",
    "blog_df['text'] = blog_df['text'].apply(lambda x: ''.join(c for c in x if 0 < ord(c) < 127) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JAW5cud6Pg0",
    "outputId": "7693fe70-4061-4e34-da9b-8a98215514b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDBdIVMp6hgP"
   },
   "source": [
    "2. Preprocess unstructured data to make it consumable for model training.\n",
    "\n",
    "- A. Eliminate All special Characters and Numbers \n",
    "- B. Lowercase all textual data \n",
    "- C. Remove all Stopwords\n",
    "- D. Remove all extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dWLxqFyZ61f_"
   },
   "outputs": [],
   "source": [
    "# Eliminate All special Characters and numbers\n",
    "blog_df['text'] = blog_df['text'].apply(lambda x: re.sub(r\"[^a-zA-Z ]\", \"\", x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOPty1YbA3PO",
    "outputId": "722081ce-95da-423e-98af-7fd83929c271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Info has been found   pages and  MB of pdf files Now i have to wait untill our team leader has processed it and learns html         \n"
     ]
    }
   ],
   "source": [
    "print( blog_df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WrIgFW_I_2fY"
   },
   "outputs": [],
   "source": [
    "# Convert all textual data to lowercase\n",
    "blog_df['text'] = blog_df['text'].apply(lambda x: x.lower() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rh_yZce-BKE5",
    "outputId": "ebd3aeb2-474e-46fb-fac6-2fad1e4a86ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Remove all Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "engStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RvtbtZMHFOIG"
   },
   "outputs": [],
   "source": [
    "blog_df['text'] = blog_df['text'].apply(lambda x:  ' '.join([word for word in x.split() if word not in engStopWords]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iU1GGMFxHQ98"
   },
   "outputs": [],
   "source": [
    "# Remove all extra white spaces\n",
    "blog_df['text'] = blog_df['text'].apply(lambda x:  re.sub(\" +\", \" \",x.strip()) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IvKofe2wFca"
   },
   "source": [
    "Q 3. Build a base Classification model\n",
    "- A. Create dependent and independent variables  Hint: Treat ‘topic’ as a Target variable.\n",
    "- B. Split data into train and test.\n",
    "- C. Vectorize data using any one vectorizer.\n",
    "- D. Build a base model for Supervised Learning - Classification.\n",
    "- E. Clearly print Performance Metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjvJUvgkwX1N"
   },
   "source": [
    "Split the dataframe columns topic as y target classifier column and rest of the columns as training input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-N31aSaURgV",
    "outputId": "0546dcbd-f374-4f0b-d6e2-74777772ba25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LvqP1u9mTqGP"
   },
   "outputs": [],
   "source": [
    "# Convert the training data into categorical values -  Convert topic, Gender and Sign features to categorical values using oneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "blog_df['gender'] = blog_df['gender'].astype('category')\n",
    "blog_df['sign'] = blog_df['sign'].astype('category')\n",
    "blog_df['topic'] = blog_df['topic'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AcEEg2W6VYUG"
   },
   "outputs": [],
   "source": [
    "blog_df['gen_cat'] = blog_df['gender'].cat.codes\n",
    "blog_df['sign_cat']  = blog_df['sign'].cat.codes\n",
    "blog_df['topic_cat']  = blog_df['topic'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VZCePg_Eut7k",
    "outputId": "9865f060-73fe-4704-c3fa-55464b2f11ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-aeebbaf8-ab27-4c39-a492-e7261c9651f1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>gen_cat</th>\n",
       "      <th>sign_cat</th>\n",
       "      <th>topic_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29489</th>\n",
       "      <td>3866560</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>hello everyone said earlier wouldnt writing ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629883</th>\n",
       "      <td>3131734</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>happy happy today happy day hehehe went meet c...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281010</th>\n",
       "      <td>958176</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>02,June,2004</td>\n",
       "      <td>heheh good heavens childe sounds like horrid s...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424094</th>\n",
       "      <td>1298624</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>21,August,2003</td>\n",
       "      <td>arrives today laptop shipped yesterday arrived...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245647</th>\n",
       "      <td>1237310</td>\n",
       "      <td>male</td>\n",
       "      <td>38</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>27,June,2004</td>\n",
       "      <td>place sun directed george stevens tragic famil...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeebbaf8-ab27-4c39-a492-e7261c9651f1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-aeebbaf8-ab27-4c39-a492-e7261c9651f1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-aeebbaf8-ab27-4c39-a492-e7261c9651f1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id gender  age        topic         sign            date  \\\n",
       "29489   3866560   male   17       indUnk       Pisces    09,July,2004   \n",
       "629883  3131734   male   24  Engineering  Sagittarius    03,July,2004   \n",
       "281010   958176   male   17   Non-Profit       Gemini    02,June,2004   \n",
       "424094  1298624   male   25   Technology        Aries  21,August,2003   \n",
       "245647  1237310   male   38         Arts       Taurus    27,June,2004   \n",
       "\n",
       "                                                     text  gen_cat  sign_cat  \\\n",
       "29489   hello everyone said earlier wouldnt writing ev...        1         7   \n",
       "629883  happy happy today happy day hehehe went meet c...        1         8   \n",
       "281010  heheh good heavens childe sounds like horrid s...        1         4   \n",
       "424094  arrives today laptop shipped yesterday arrived...        1         1   \n",
       "245647  place sun directed george stevens tragic famil...        1        10   \n",
       "\n",
       "        topic_cat  \n",
       "29489          39  \n",
       "629883         14  \n",
       "281010         28  \n",
       "424094         35  \n",
       "245647          4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "znWPKbLt-xI4"
   },
   "outputs": [],
   "source": [
    "# Create dependent and independent variables \n",
    "X = blog_df['text']\n",
    "Y = blog_df['topic_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "46FnDQjawXtO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yHZXpA84Dx5x"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test.\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gcoITwcXDxzi"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25, random_state=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0edeEKlKDxni",
    "outputId": "60c5d34e-30b8-48a5-e6d9-53b8cf8bd58a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "# Vectorize data \n",
    "\n",
    "# build Vocabulary\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "blog_voc = set()\n",
    "for index, row in blog_df.iterrows():\n",
    "    blog_voc.update(word_tokenize(row['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "V0iV5O0A3WQ3"
   },
   "outputs": [],
   "source": [
    "blog_voc = list(blog_voc)\n",
    "word_index = {w: index for index, w in enumerate(blog_voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "W2rQLPfF3loq"
   },
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = len(blog_voc)\n",
    "DOCUMENTS_COUNT = len(blog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1WHcdxG3lbo",
    "outputId": "242757e0-d541-4be1-f04a-16b9d75db55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279146 68128\n"
     ]
    }
   ],
   "source": [
    "print( VOCABULARY_SIZE, DOCUMENTS_COUNT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "RKQtdXE_a-vP"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower() for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Cfv9-C_0Y24M"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer( stop_words = engStopWords, tokenizer=tokenize, vocabulary=blog_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSmGF8p6Yccp",
    "outputId": "949b8bb8-d51b-401e-e443-2790910cbdc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function tokenize at 0x7fd14d52fb90>,\n",
       "                vocabulary=['dartboard', 'gorgon', 'azukeru', 'alafaya',\n",
       "                            'fuhreakin', 'hutchtemmel', 'loachs', 'memawo',\n",
       "                            'halsey', 'bindoffs', 'ltly', 'justnbspcrashed',\n",
       "                            'floorall', 'manhahas', 'nightdrunk', 'allcotton',\n",
       "                            'almontybut', 'mobihome', 'phewkinda', 'lemeans',\n",
       "                            'ocala', 'herepost', 'fabo', 'boredstressed',\n",
       "                            'ludicrousness', 'wweeeeee', 'bet', 'minty',\n",
       "                            'flockfileop', 'rushing', ...])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tdv4Elcbm5F",
    "outputId": "36b4a488-bc90-49d9-ab52-2a452ea95010"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51096, 279146)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the data and transform to feature matrix\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ppcudHoCsY8w"
   },
   "outputs": [],
   "source": [
    "# Build a base model for Supervised Learning - Classification.\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mDkpNSOktlXD"
   },
   "outputs": [],
   "source": [
    "#svmClsfr = svm.SVC(kernel='linear', probability=True)\n",
    "#svmClsfr.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JsbQxdgvyWmw"
   },
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss='log', random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVszIq6DIJXP",
    "outputId": "c5d60253-616f-4066-cef6-bccefbd8184d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdowwrHdcSxo",
    "outputId": "c73a4b72-f2c7-4c66-cff3-ab4071ae5429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41302645999686866\n"
     ]
    }
   ],
   "source": [
    "sgd_scores = sgd_clf.score( X_train_tfidf, y_train)\n",
    "print(sgd_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iw5AVX5RHOZi",
    "outputId": "cecda9b7-556e-4a68-dac3-d908ef918a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17032, 279146)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clearly print Performance Metrics.\n",
    "# Fit to the test data and transform to feature matrix\n",
    "X_test_tfidf = tfidf.fit_transform(X_test)\n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WSEdq3iMLr-K"
   },
   "outputs": [],
   "source": [
    "pred_test = sgd_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ge5-4DsLLrvI",
    "outputId": "96eda821-efdc-4b5d-b172-d093ea7ce57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.39\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=accuracy_score(y_test, pred_test)\n",
    "\n",
    "print('Test Accuracy: ',np.round(test_accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nQh-7oj7SKUm"
   },
   "outputs": [],
   "source": [
    "y_train_pred = sgd_clf.decision_function(X_train_tfidf)    \n",
    "y_test_pred = sgd_clf.decision_function(X_test_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9KjTwjnaU7By"
   },
   "outputs": [],
   "source": [
    "pred_log_test = sgd_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yv8fWV2JutWF",
    "outputId": "4731136c-1c72-44ee-c869-10f64da9addd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 39, 39, ..., 39, 39, 39], dtype=int8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Hwbf1p9EvBEX"
   },
   "outputs": [],
   "source": [
    "# Calculate and print the confusion matrix for the KNN trainded model on test data score\n",
    "#cm_sgd = confusion_matrix( pred_log_test, y_test)\n",
    "\n",
    "#df_sgd_knn = pd.DataFrame(cm_sgd, index = [i for i in [\"1\",\"0\"]],\n",
    "                  #columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n",
    "#plt.figure(figsize = (7,5))\n",
    "#sns.heatmap(df_sgd_knn, annot=True, fmt='d' , cmap='Blues' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "at033KsyKF5W"
   },
   "outputs": [],
   "source": [
    "#AUC ROC curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(sgd_clf, cv='prefit')\n",
    "#model=calibrator.fit(X_train_tfidf, y_train)\n",
    "#y_test_pred = \n",
    "\n",
    "# Print the ROC AUC curve\n",
    "#sg_roc_auc = roc_auc_score(y_test, sgd_clf.predict_proba(X_test_tfidf), multi_class='ovr' )\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(X_test_tfidf))\n",
    "#plt.figure()\n",
    "#plt.plot(fpr, tpr, label='(area = %0.2f)' % sg_roc_auc)\n",
    "#plt.plot([0, 1], [0, 1],'r--',label='No Skill')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver operating characteristic')\n",
    "#plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5YpATp7RYAn"
   },
   "source": [
    "***4. Improve Performance of model.***\n",
    "- A. Experiment with other vectorisers. \n",
    "- B. Build classifier Models using other algorithms than base model.\n",
    "- C. Tune Parameters/Hyperparameters of the model/s.\n",
    "- D. Clearly print Performance Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8r8SphRGRVko"
   },
   "outputs": [],
   "source": [
    "# creating the feature matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "CntVecz = CountVectorizer(max_features=1000)\n",
    "X_CV = CntVecz.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Dk2sU8xkSSz3"
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_CV,Y, test_size=0.25, random_state=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bh4DAIjkSSsV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Building a Support Vector Machine on train data\n",
    "#svc_model = SVC(C= .1, kernel='linear', gamma= 1, random_state=1)\n",
    "#svc_model.fit(X_train1, y_train1)\n",
    "\n",
    "#prediction = svc_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg7uz6-znT3U",
    "outputId": "47f3b28e-65d4-482c-b301-c28bb2187993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3, weights='distance')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import zscore\n",
    "KNN_Classifiers = KNeighborsClassifier(n_neighbors=3, weights = 'distance')\n",
    "\n",
    "# Train the model with  data \n",
    "KNN_Classifiers.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzfDEdeznmtQ",
    "outputId": "7b11a55f-8a75-4f16-d229-1f5f3d29b3c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21823626115547204"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_knn = KNN_Classifiers.predict(X_test1)\n",
    "KNN_Classifiers.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Vv3D2csOnuou"
   },
   "outputs": [],
   "source": [
    "#  Tune Parameters \n",
    "from sklearn import metrics\n",
    "k_values = [11,13,15, 17,19,21,23,25]\n",
    "scores = {}\n",
    "scores_list = []\n",
    "for k in k_values:\n",
    "   KNNClsfr = KNeighborsClassifier(n_neighbors=k)\n",
    "   KNNClsfr.fit(X_train1, y_train1)\n",
    "   y_pred1 = KNNClsfr.predict(X_test1)\n",
    "   scores[k] = metrics.accuracy_score(y_test1,y_pred1)\n",
    "   scores_list.append(metrics.accuracy_score(y_test1,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nrlxby6Hs7ID",
    "outputId": "42df9abb-e117-4387-ee24-a67c51a919d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   1    0    0 ...    0    0   74]\n",
      " [   0    0    0 ...    0    0   83]\n",
      " [   0    0    0 ...    0    0   23]\n",
      " ...\n",
      " [   0    0    0 ...    0    0   41]\n",
      " [   0    0    0 ...    0    8   34]\n",
      " [   0    0    0 ...    0    1 4710]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02        96\n",
      "           1       0.00      0.00      0.00       112\n",
      "           2       0.00      0.00      0.00        31\n",
      "           3       0.00      0.00      0.00        29\n",
      "           4       0.10      0.00      0.00       816\n",
      "           5       0.00      0.00      0.00        41\n",
      "           6       0.00      0.00      0.00        90\n",
      "           7       0.00      0.00      0.00        55\n",
      "           8       0.67      0.02      0.04       110\n",
      "           9       0.00      0.00      0.00       125\n",
      "          10       0.00      0.00      0.00       493\n",
      "          11       0.00      0.00      0.00        28\n",
      "          12       0.00      0.00      0.00       141\n",
      "          13       0.07      0.00      0.01       712\n",
      "          14       0.00      0.00      0.00       287\n",
      "          15       0.00      0.00      0.00        17\n",
      "          16       0.00      0.00      0.00       126\n",
      "          17       0.00      0.00      0.00       171\n",
      "          18       0.00      0.00      0.00        78\n",
      "          19       0.00      0.00      0.00       399\n",
      "          20       0.00      0.00      0.00        34\n",
      "          21       0.17      0.00      0.01       213\n",
      "          22       0.00      0.00      0.00        35\n",
      "          23       0.00      0.00      0.00        63\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00       142\n",
      "          26       0.00      0.00      0.00        79\n",
      "          27       0.00      0.00      0.00        99\n",
      "          28       0.00      0.00      0.00       403\n",
      "          29       0.00      0.00      0.00       178\n",
      "          30       0.00      0.00      0.00        71\n",
      "          31       0.00      0.00      0.00       120\n",
      "          32       0.00      0.00      0.00       176\n",
      "          33       0.00      0.00      0.00        86\n",
      "          34       0.27      0.30      0.28      3806\n",
      "          35       0.14      0.01      0.02      1079\n",
      "          36       0.00      0.00      0.00       103\n",
      "          37       0.00      0.00      0.00        51\n",
      "          38       0.89      0.14      0.25        56\n",
      "          39       0.37      0.75      0.50      6266\n",
      "\n",
      "    accuracy                           0.35     17032\n",
      "   macro avg       0.09      0.03      0.03     17032\n",
      "weighted avg       0.23      0.35      0.25     17032\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "result = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = metrics.classification_report(y_test1, y_pred1)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "LqApxHVqtPQU",
    "outputId": "8a0ec293-a60c-4715-f97e-643989223499"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_values,scores_list)\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6AwMKIl94Pt"
   },
   "source": [
    "***5. Share insights on relative performance comparison***\n",
    "- A. Which vectorizer performed better? Probable reason?.\n",
    "- B. Which model outperformed? Probable reason?\n",
    "- C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?\n",
    "- D. According to you, which performance metric should be\n",
    "given most importance, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j6W-TCkrrcr"
   },
   "source": [
    "***Which vectorizer performed better? Probable reason?.***\n",
    "TFIDF performed better compared to countvectorizer.\n",
    "But count vectorizer showed improvement on increasing the neighbour count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x0WFsQgrzn1"
   },
   "source": [
    "***B. Which model outperformed? Probable reason?***\n",
    "SGDClassifier outperformed Nearest Neighbour.  SGDClassifier uses a sample data to detemine the Gradient decent and finds the optimum value.\n",
    "Logisitic Regression and SVM took more compuatation time and did not complete even after activiating GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj0CN_I_sk46"
   },
   "source": [
    "***C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?***\n",
    "Increasing the neigbhour count improved the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fM4YtQtsw4H"
   },
   "source": [
    "***D. According to you, which performance metric should be given most importance, why?***\n",
    "The ROC would reflect the better performance of the model.  As this is a multi-class classification,  Determining ROC for multiple class is challenging and might not provide the actual performance.  \n",
    "Confusion matrix and classification report  (precision and Recall) might be referred for classification performance \n",
    "Accuracy might vary based on the sample test data but can provide a high level lean of the performance indicator towards less or more accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKmeYQZvuUi3"
   },
   "source": [
    "*** DOMAIN: Customer support ***\n",
    "\n",
    "- • CONTEXT: Great Learning has a an academic support department which receives numerous support requests every day throughout the year.\n",
    "Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request to an actual human support executive if the request is complex or not in it’s database.\n",
    "\n",
    "- • DATA DESCRIPTION: A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics skills.\n",
    "\n",
    "- • PROJECT OBJECTIVE: Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "\n",
    " 1. Start chat session with greetings and ask what the user is looking for. \n",
    "\n",
    "2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus. \n",
    "\n",
    "3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it. Hint: There are a lot of techniques using which one can clean and prepare the data which can be used to train a ML/DL classifier. Hence, it might require you to experiment, research, self learn and implement the above classifier. There might be many iterations between hand building the corpus and designing the best fit text classifier. As the quality and quantity of corpus increases the model’s performance i.e. ability to answer right questions also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "1Fjb8Z4Oy2qK"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8W9qIRU_y25g"
   },
   "outputs": [],
   "source": [
    "project_path1 = '/content/drive/My Drive/Colab Notebooks/NLTP/'\n",
    "file_path1 = project_path1 + 'GL_Bot_New.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "CP0gu1g-y28V"
   },
   "outputs": [],
   "source": [
    "# Read the json corpus data\n",
    "import json\n",
    "json_data = json.loads( open( file_path1 ).read( ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "uTKpzXIgy2_A"
   },
   "outputs": [],
   "source": [
    "corps_voc = set()\n",
    "corps_tags = []\n",
    "corps_word_tag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zXtoD4sy3Bj",
    "outputId": "fdf10100-0448-4e98-ce06-f0159189e846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techniques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Transferring the request to your PM'], 'context_set': ''}, {'tag': 'GL', 'patterns': ['Great Learning', 'Certificate Courses', 'AIML', 'Data Science and Business Analytics', 'Management', 'Bootcamps', 'Cloud Computing', 'Cyber Security', 'Software Development', 'Digital Marketing & Sales', 'Design Thinking'], 'responses': ['Please visit www.MyGreatLearning.com', 'Explore the Great Learning', 'Learn new skills with Great Learning Program'], 'context_set': ''}]}\n"
     ]
    }
   ],
   "source": [
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7esIvSpLy3EO",
    "outputId": "36389204-ac5c-4dba-b347-8b29908a8b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['hi'], 'Intro'), (['how', 'are', 'you'], 'Intro'), (['is', 'anyone', 'there'], 'Intro'), (['hello'], 'Intro'), (['whats', 'up'], 'Intro'), (['hey'], 'Intro'), (['yo'], 'Intro'), (['listen'], 'Intro'), (['please', 'help', 'me'], 'Intro'), (['i', 'am', 'learner', 'from'], 'Intro'), (['i', 'belong', 'to'], 'Intro'), (['aiml', 'batch'], 'Intro'), (['aifl', 'batch'], 'Intro'), (['i', 'am', 'from'], 'Intro'), (['my', 'pm', 'is'], 'Intro'), (['blended'], 'Intro'), (['online'], 'Intro'), (['i', 'am', 'from'], 'Intro'), (['hey', 'ya'], 'Intro'), (['talking', 'to', 'you', 'for', 'first', 'time'], 'Intro'), (['thank', 'you'], 'Exit'), (['thanks'], 'Exit'), (['cya'], 'Exit'), (['see', 'you'], 'Exit'), (['later'], 'Exit'), (['see', 'you', 'later'], 'Exit'), (['goodbye'], 'Exit'), (['i', 'am', 'leaving'], 'Exit'), (['have', 'a', 'Good', 'day'], 'Exit'), (['you', 'helped', 'me'], 'Exit'), (['thanks', 'a', 'lot'], 'Exit'), (['thanks', 'a', 'ton'], 'Exit'), (['you', 'are', 'the', 'best'], 'Exit'), (['great', 'help'], 'Exit'), (['too', 'good'], 'Exit'), (['you', 'are', 'a', 'good', 'learning', 'buddy'], 'Exit'), (['olympus'], 'Olympus'), (['explain', 'me', 'how', 'olympus', 'works'], 'Olympus'), (['I', 'am', 'not', 'able', 'to', 'understand', 'olympus'], 'Olympus'), (['olympus', 'window', 'not', 'working'], 'Olympus'), (['no', 'access', 'to', 'olympus'], 'Olympus'), (['unable', 'to', 'see', 'link', 'in', 'olympus'], 'Olympus'), (['no', 'link', 'visible', 'on', 'olympus'], 'Olympus'), (['whom', 'to', 'contact', 'for', 'olympus'], 'Olympus'), (['lot', 'of', 'problem', 'with', 'olympus'], 'Olympus'), (['olypus', 'is', 'not', 'a', 'good', 'tool'], 'Olympus'), (['lot', 'of', 'problems', 'with', 'olympus'], 'Olympus'), (['how', 'to', 'use', 'olympus'], 'Olympus'), (['teach', 'me', 'olympus'], 'Olympus'), (['i', 'am', 'not', 'able', 'to', 'understand', 'svm'], 'SL'), (['explain', 'me', 'how', 'machine', 'learning', 'works'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'ensemble', 'techniques'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'knn'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'boosting'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting'], 'SL'), (['machine', 'learning'], 'SL'), (['ML'], 'SL'), (['SL'], 'SL'), (['supervised', 'learning'], 'SL'), (['knn'], 'SL'), (['logistic', 'regression'], 'SL'), (['regression'], 'SL'), (['classification'], 'SL'), (['naive', 'bayes'], 'SL'), (['nb'], 'SL'), (['ensemble', 'techniques'], 'SL'), (['bagging'], 'SL'), (['boosting'], 'SL'), (['ada', 'boosting'], 'SL'), (['ada'], 'SL'), (['gradient', 'boosting'], 'SL'), (['hyper', 'parameters'], 'SL'), (['what', 'is', 'deep', 'learning'], 'NN'), (['unable', 'to', 'understand', 'deep', 'learning'], 'NN'), (['explain', 'me', 'how', 'deep', 'learning', 'works'], 'NN'), (['i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning'], 'NN'), (['not', 'able', 'to', 'understand', 'neural', 'nets'], 'NN'), (['very', 'diffult', 'to', 'understand', 'neural', 'nets'], 'NN'), (['unable', 'to', 'understand', 'neural', 'nets'], 'NN'), (['ann'], 'NN'), (['artificial', 'intelligence'], 'NN'), (['artificial', 'neural', 'networks'], 'NN'), (['weights'], 'NN'), (['activation', 'function'], 'NN'), (['hidden', 'layers'], 'NN'), (['softmax'], 'NN'), (['sigmoid'], 'NN'), (['relu'], 'NN'), (['otimizer'], 'NN'), (['forward', 'propagation'], 'NN'), (['backward', 'propagation'], 'NN'), (['epochs'], 'NN'), (['epoch'], 'NN'), (['what', 'is', 'an', 'epoch'], 'NN'), (['adam'], 'NN'), (['sgd'], 'NN'), (['what', 'is', 'your', 'name'], 'Bot'), (['who', 'are', 'you'], 'Bot'), (['name', 'please'], 'Bot'), (['when', 'are', 'your', 'hours', 'of', 'opertions'], 'Bot'), (['what', 'are', 'your', 'working', 'hours'], 'Bot'), (['hours', 'of', 'operation'], 'Bot'), (['working', 'hours'], 'Bot'), (['hours'], 'Bot'), (['what', 'the', 'hell'], 'Profane'), (['bloody', 'stupid', 'bot'], 'Profane'), (['do', 'you', 'think', 'you', 'are', 'very', 'smart'], 'Profane'), (['screw', 'you'], 'Profane'), (['i', 'hate', 'you'], 'Profane'), (['you', 'are', 'stupid'], 'Profane'), (['jerk'], 'Profane'), (['you', 'are', 'a', 'joke'], 'Profane'), (['useless', 'piece', 'of', 'shit'], 'Profane'), (['my', 'problem', 'is', 'not', 'solved'], 'Ticket'), (['you', 'did', 'not', 'help', 'me'], 'Ticket'), (['not', 'a', 'good', 'solution'], 'Ticket'), (['bad', 'solution'], 'Ticket'), (['not', 'good', 'solution'], 'Ticket'), (['no', 'help'], 'Ticket'), (['wasted', 'my', 'time'], 'Ticket'), (['useless', 'bot'], 'Ticket'), (['create', 'a', 'ticket'], 'Ticket'), (['Great', 'Learning'], 'GL'), (['Certificate', 'Courses'], 'GL'), (['AIML'], 'GL'), (['Data', 'Science', 'and', 'Business', 'Analytics'], 'GL'), (['Management'], 'GL'), (['Bootcamps'], 'GL'), (['Cloud', 'Computing'], 'GL'), (['Cyber', 'Security'], 'GL'), (['Software', 'Development'], 'GL'), (['Digital', 'Marketing', '&', 'Sales'], 'GL'), (['Design', 'Thinking'], 'GL')]\n"
     ]
    }
   ],
   "source": [
    "# Iterate JSOn data and load contents (Corpus has Intents that has a structure\n",
    "# tag - High level group\n",
    "# patterns - possible inputs from user for training the model\n",
    "# response -  List of responses that can be provided randomly if more than one response is available\n",
    "# \n",
    "for Intent_item in json_data['intents']:\n",
    "  # collate the tags\n",
    "  tag = Intent_item['tag'] \n",
    "  corps_tags.append( tag )\n",
    "  for pattern in Intent_item['patterns']:\n",
    "    words = word_tokenize( pattern )\n",
    "    corps_voc.update( words )\n",
    "    corps_word_tag.append( (words , tag) )\n",
    "\n",
    "print(corps_word_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0zhBDsOzWcw",
    "outputId": "65a82a36-a80e-40f7-d929-31052868f663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "['talking', 'create', 'sgd', 'classification', 'i', 'listen', 'use', 'belong', 'explain', 'learner', 'what', 'my', 'hours', 'AIML', 'ensemble', 'who', 'Cloud', 'intelligence', 'function', 'Data', 'layers', 'hell', 'svm', 'able', 'hyper', 'Good', 'olympus', 'cya', 'did', '&', 'working', 'SL', 'supervised', 'piece', 'Certificate', 'Learning', 'knn', 'I', 'bloody', 'blended', 'random', 'too', 'good', 'weights', 'logistic', 'hate', 'naive', 'activation', 'machine', 'aifl', 'softmax', 'hi', 'when', 'backward', 'regression', 'window', 'anyone', 'ton', 'stupid', 'wasted', 'me', 'pm', 'goodbye', 'Software', 'Design', 'in', 'works', 'ML', 'forest', 'helped', 'for', 'adam', 'whats', 'leaving', 'gradient', 'networks', 'Sales', 'with', 'operation', 'great', 'jerk', 'ya', 'understand', 'opertions', 'neural', 'have', 'Thinking', 'first', 'not', 'please', 'aiml', 'best', 'thanks', 'see', 'contact', 'problems', 'are', 'screw', 'epoch', 'Marketing', 'forward', 'solved', 'visible', 'a', 'bayes', 'link', 'bot', 'an', 'unable', 'boosting', 'bad', 'yo', 'on', 'epochs', 'Business', 'nets', 'propagation', 'problem', 'Cyber', 'olypus', 'validation', 'ada', 'day', 'Science', 'otimizer', 'later', 'Management', 'the', 'shit', 'diffult', 'hello', 'batch', 'think', 'am', 'hey', 'Development', 'access', 'Bootcamps', 'cross', 'name', 'Analytics', 'there', 'nb', 'very', 'Security', 'learning', 'no', 'hidden', 'solution', 'whom', 'smart', 'help', 'is', 'of', 'to', 'thank', 'teach', 'Digital', 'parameters', 'sigmoid', 'your', 'Great', 'lot', 'ann', 'techniques', 'relu', 'and', 'imputer', 'tool', 'you', 'bagging', 'buddy', 'up', 'joke', 'ticket', 'how', 'from', 'time', 'useless', 'deep', 'Courses', 'do', 'online', 'Computing', 'artificial']\n"
     ]
    }
   ],
   "source": [
    "corps_voc = list( corps_voc )\n",
    "print(len(corps_voc))\n",
    "print(corps_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gAOg4tAzWfW",
    "outputId": "c07e5ee8-f8e3-4f03-f47e-9a794c50ac3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intro', 'Exit', 'Olympus', 'SL', 'NN', 'Bot', 'Profane', 'Ticket', 'GL']\n"
     ]
    }
   ],
   "source": [
    "print( corps_tags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gp56uoKIzWhs",
    "outputId": "128e46ef-9a9f-4fe4-8602-28ddce653b91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "# Create a list of spl characters\n",
    "spl_chars = ['~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '-', '\"', '*', '|', ',', '&', '<', '`', '}', '.', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/']\n",
    "wnl = WordNetLemmatizer()\n",
    "corps_voc = [ wnl.lemmatize(word)  for word in corps_voc if word not in spl_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEsUMpzYzWkE",
    "outputId": "0abd7f2b-af77-4d63-fb82-ed4fbdbe9cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "print(len(corps_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqsJZwpizWmL",
    "outputId": "6db2f7d3-32c6-4bdb-ef38-c7713f189dfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data \n",
    "training_data = []\n",
    "output_empty = [0] * len(corps_tags)\n",
    "for document in corps_word_tag:\n",
    "  bag = []\n",
    "  word_patterns = document[0]\n",
    "  word_patterns = [wnl.lemmatize (word.lower()) for word in word_patterns]\n",
    "  for word in corps_voc:\n",
    "    bag.append(1) if word in word_patterns else bag. append (0)\n",
    "  output_row = list (output_empty)\n",
    "  output_row[corps_tags.index(document[1])] = 1\n",
    "  training_data.append ([bag, output_row])\n",
    "\n",
    "random.shuffle(training_data)\n",
    "training_data = np.array(training_data)\n",
    "X_train = list(training_data[:, 0])\n",
    "y_train = list(training_data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmQJiSWyzoXp",
    "outputId": "e2baa460-bc45-4b41-ffb0-16cad41030be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 2)\n",
      "184\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)\n",
    "print(len(X_train[0]))\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "2dOQo-lqzobA"
   },
   "outputs": [],
   "source": [
    "#import the tensorflow packages\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mSnBmVKTzoeZ"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add (Dense (128, input_shape=(len(X_train[0]),), activation='relu'))\n",
    "model.add (Dropout(0.5))\n",
    "model.add( Dense( 64, activation='relu' ) )\n",
    "model.add (Dropout(0.5))\n",
    "model.add( Dense( 32, activation='relu' ) )\n",
    "\n",
    "model.add( Dense( len(y_train[0]), activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "d1xOf4gq0KsU"
   },
   "outputs": [],
   "source": [
    "opt_sgd = SGD(learning_rate=0.01)\n",
    "model.compile( loss='categorical_crossentropy', optimizer=opt_sgd , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsA5pN-20Ku7",
    "outputId": "4129ca81-4204-4376-c3f1-d531474c6408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DazxnaK00UIP",
    "outputId": "b5190c52-47ea-40bf-8e70-3ec77b3b27e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 2ms/step - loss: 2.2098 - accuracy: 0.1439\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1762 - accuracy: 0.2446\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1631 - accuracy: 0.2086\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1555 - accuracy: 0.1942\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1301 - accuracy: 0.2230\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1151 - accuracy: 0.1942\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1088 - accuracy: 0.2302\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.1166 - accuracy: 0.2086\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0698 - accuracy: 0.2086\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0792 - accuracy: 0.2158\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0798 - accuracy: 0.2014\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0617 - accuracy: 0.2086\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0805 - accuracy: 0.2158\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.0710 - accuracy: 0.1942\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0408 - accuracy: 0.2230\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.0149 - accuracy: 0.2302\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0236 - accuracy: 0.2374\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0191 - accuracy: 0.2158\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0023 - accuracy: 0.2230\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9867 - accuracy: 0.2302\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0151 - accuracy: 0.2230\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0079 - accuracy: 0.2518\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 2.0142 - accuracy: 0.1871\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9677 - accuracy: 0.2158\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9800 - accuracy: 0.2230\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9724 - accuracy: 0.2374\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9462 - accuracy: 0.2302\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9423 - accuracy: 0.2950\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9547 - accuracy: 0.2518\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9657 - accuracy: 0.2806\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9374 - accuracy: 0.2590\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9242 - accuracy: 0.3022\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.9487 - accuracy: 0.2734\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9098 - accuracy: 0.2734\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.9041 - accuracy: 0.3237\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8916 - accuracy: 0.3022\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8707 - accuracy: 0.2950\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8989 - accuracy: 0.2446\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.9124 - accuracy: 0.3022\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8788 - accuracy: 0.2950\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7972 - accuracy: 0.3237\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8458 - accuracy: 0.3597\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8762 - accuracy: 0.2590\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8510 - accuracy: 0.3381\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7809 - accuracy: 0.3094\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.8279 - accuracy: 0.3525\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7899 - accuracy: 0.3525\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7615 - accuracy: 0.3525\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7977 - accuracy: 0.3165\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7479 - accuracy: 0.4029\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7405 - accuracy: 0.3885\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7612 - accuracy: 0.4029\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6864 - accuracy: 0.4029\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6963 - accuracy: 0.4245\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6804 - accuracy: 0.4029\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.7148 - accuracy: 0.4029\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6504 - accuracy: 0.4388\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6996 - accuracy: 0.3525\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6564 - accuracy: 0.4388\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.6671 - accuracy: 0.3741\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6048 - accuracy: 0.4820\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.5728 - accuracy: 0.4388\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6223 - accuracy: 0.4460\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.5093 - accuracy: 0.4892\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5497 - accuracy: 0.4676\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.5140 - accuracy: 0.4748\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.4997 - accuracy: 0.5252\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.5448 - accuracy: 0.4604\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.4980 - accuracy: 0.4964\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.4489 - accuracy: 0.5468\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.3734 - accuracy: 0.5180\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.4390 - accuracy: 0.4748\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.4007 - accuracy: 0.5540\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.3085 - accuracy: 0.5396\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.3497 - accuracy: 0.5252\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.3791 - accuracy: 0.5252\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.2936 - accuracy: 0.5683\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3186 - accuracy: 0.4892\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.3135 - accuracy: 0.4820\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.2574 - accuracy: 0.5971\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.2433 - accuracy: 0.5683\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.2267 - accuracy: 0.6043\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.2122 - accuracy: 0.6115\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1973 - accuracy: 0.5540\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1710 - accuracy: 0.5827\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.1635 - accuracy: 0.5971\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1209 - accuracy: 0.6115\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1673 - accuracy: 0.5683\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0875 - accuracy: 0.6115\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1224 - accuracy: 0.6835\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0915 - accuracy: 0.6763\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.0545 - accuracy: 0.6475\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1276 - accuracy: 0.6259\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0168 - accuracy: 0.6547\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.1561 - accuracy: 0.5755\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0621 - accuracy: 0.6763\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0310 - accuracy: 0.6259\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9775 - accuracy: 0.7338\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0466 - accuracy: 0.6403\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0601 - accuracy: 0.6763\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0418 - accuracy: 0.6619\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.0267 - accuracy: 0.6115\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9563 - accuracy: 0.6691\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9268 - accuracy: 0.6763\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9938 - accuracy: 0.6187\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9599 - accuracy: 0.6475\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9457 - accuracy: 0.6978\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8243 - accuracy: 0.7338\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.6763\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8554 - accuracy: 0.7266\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8535 - accuracy: 0.7050\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.8555 - accuracy: 0.7050\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8682 - accuracy: 0.7050\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8691 - accuracy: 0.6906\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8473 - accuracy: 0.7338\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7881 - accuracy: 0.7626\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8345 - accuracy: 0.7194\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7469 - accuracy: 0.7554\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7762 - accuracy: 0.7554\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8034 - accuracy: 0.7266\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.7338\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8335 - accuracy: 0.7194\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.7626\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.7554\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7554\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7433 - accuracy: 0.7626\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.7986\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.7842\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.7626\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.8273\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.7914\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.7842\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8138 - accuracy: 0.7194\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.8129\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.8417\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.7194\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.7842\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.8058\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 0.8273\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8417\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.8417\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8417\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.8058\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.8129\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.8129\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.8417\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8993\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7986\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.8273\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8849\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.8705\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.8058\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8129\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.8273\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8993\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8561\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8777\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.8561\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8849\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8633\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8345\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8489\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8777\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8273\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8489\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8489\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8345\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8849\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8921\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8777\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8633\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8993\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8777\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8705\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.9209\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.9353\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.9065\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8921\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.9065\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8993\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.9209\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.9209\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.9137\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8633\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.9065\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8705\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.9281\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8849\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8993\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.9353\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8849\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.9424\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.9353\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.9065\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9281\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.9424\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9281\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.9137\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.9281\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "# train the model by fitting the training data\n",
    "history=model.fit(np.array(X_train), np.array(y_train), epochs=200, verbose=1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "dPXCk67K0UK7"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence (sentence):\n",
    "  sentence_words = nltk.word_tokenize(sentence)\n",
    "  sentence_words = [wnl.lemmatize(word) for word in sentence_words]\n",
    "  return sentence_words\n",
    "\n",
    "\n",
    "def bag_of_words (sentence):\n",
    "  sentence_words = clean_up_sentence (sentence)\n",
    "  bag = [0] * len (corps_voc)\n",
    "  for w in sentence_words:\n",
    "    for i, word in enumerate(corps_voc) :\n",
    "      if word == w:\n",
    "        bag[i] = 1\n",
    "  return np.array (bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "6sf0NMdX0UNA"
   },
   "outputs": [],
   "source": [
    "def predict_response(sentence):\n",
    "  bow = bag_of_words (sentence.lower())\n",
    "  res = model.predict(np.array([bow]), verbose=0)[0]\n",
    "  ERROR_THRESHOLD = 0.25\n",
    "  results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "  results.sort(key=lambda x: x[1], reverse=True)\n",
    "  return_list= []\n",
    "  for r in results:\n",
    "    return_list.append({'intent': corps_tags[r[0]], 'probability' : str(r[1])})\n",
    "  return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kiUBtln0rQF",
    "outputId": "80686073-970f-4b4e-96c9-69084d73c5b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'GL', 'probability': '0.7764234'}]\n"
     ]
    }
   ],
   "source": [
    "print(predict_response('AIML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIPtRrK90rTH",
    "outputId": "d8591180-cec3-46e2-caf8-6bdea4ea3f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Running\n",
      "Welcome , Hi I am the Chatbot \n",
      "Hi\n",
      "Hello! how can i help you ?\n",
      "AIML\n",
      "Learn new skills with Great Learning Program\n",
      "Ticket\n",
      "Hello! how can i help you ?\n",
      "dont understand\n",
      "Link: Neural Nets wiki\n",
      "see you\n",
      "I hope I was able to assist you, Good Bye\n",
      "Good bye\n"
     ]
    }
   ],
   "source": [
    "def get_response(intents_list, intents_json):\n",
    "  tag = intents_list[0]['intent']\n",
    "  list_of_intents = intents_json['intents']\n",
    "  result = 'I cannot understand,  please re-phrase the question'\n",
    "  for i in list_of_intents:\n",
    "    if i['tag'] == tag:\n",
    "      result = random.choice(i['responses'])\n",
    "      break\n",
    "  return result\n",
    "\n",
    "print (\"Bot Running\")\n",
    "print(\"Welcome , Hi I am the Chatbot \")\n",
    "\n",
    "\n",
    "exit_intent = 'Exit'\n",
    "chat_alive = True\n",
    "while chat_alive:\n",
    "  message = input(\"\")\n",
    "  ints = predict_response(message.lower())\n",
    "  if(ints[0]['intent'] == exit_intent):\n",
    "    chat_alive = False\n",
    "  res = get_response (ints, json_data)\n",
    "  print(res)\n",
    "\n",
    "print('Good bye')  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
